{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.read_html('https://en.wikipedia.org/wiki/Chi-squared_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[     Unnamed: 0    A    B    C    D  total\n",
       " 0  White collar   90   60  104   95    349\n",
       " 1   Blue collar   30   50   51   20    151\n",
       " 2     No collar   30   40   45   35    150\n",
       " 3         Total  150  150  200  150    650,\n",
       "    .mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}.mw-parser-output .infobox .navbar{font-size:100%}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}vteStatistics  \\\n",
       " 0                                       Outline Index                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       " 1   Descriptive statisticsContinuous dataCenter Me...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       " 2                              Descriptive statistics                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       " 3   Continuous dataCenter Mean arithmetic geometri...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       " 4                                     Continuous data                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       " ..                                                ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       " 60                                      Biostatistics                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       " 61                             Engineering statistics                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       " 62                                  Social statistics                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       " 63                                 Spatial statistics                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       " 64  Category  Mathematics portal Commons  WikiProject                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       " \n",
       "    .mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}.mw-parser-output .infobox .navbar{font-size:100%}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}vteStatistics.1  \n",
       " 0                                       Outline Index                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       " 1   Descriptive statisticsContinuous dataCenter Me...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       " 2                              Descriptive statistics                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       " 3   Continuous dataCenter Mean arithmetic geometri...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       " 4   Center Mean arithmetic geometric harmonic Medi...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       " ..                                                ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       " 60  Bioinformatics Clinical trials / studies Epide...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       " 61  Chemometrics Methods engineering Probabilistic...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       " 62  Actuarial science Census Crime statistics Demo...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       " 63  Cartography Environmental statistics Geographi...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       " 64  Category  Mathematics portal Commons  WikiProject                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       " \n",
       " [65 rows x 2 columns],\n",
       "                               Descriptive statistics  \\\n",
       " 0  Continuous dataCenter Mean arithmetic geometri...   \n",
       " 1                                    Continuous data   \n",
       " 2                                             Center   \n",
       " 3                                         Dispersion   \n",
       " 4                                              Shape   \n",
       " 5                                         Count data   \n",
       " 6                                     Summary tables   \n",
       " 7                                         Dependence   \n",
       " 8                                           Graphics   \n",
       " \n",
       "                             Descriptive statistics.1  \n",
       " 0  Continuous dataCenter Mean arithmetic geometri...  \n",
       " 1  Center Mean arithmetic geometric harmonic Medi...  \n",
       " 2     Mean arithmetic geometric harmonic Median Mode  \n",
       " 3  Variance Standard deviation Coefficient of var...  \n",
       " 4  Central limit theorem Moments Skewness Kurtosi...  \n",
       " 5                                Index of dispersion  \n",
       " 6  Grouped data Frequency distribution Contingenc...  \n",
       " 7  Pearson product-moment correlation Rank correl...  \n",
       " 8  Bar chart Biplot Box plot Control chart Correl...  ,\n",
       "                  0                                                  1\n",
       " 0  Continuous data  Center Mean arithmetic geometric harmonic Medi...\n",
       " 1           Center     Mean arithmetic geometric harmonic Median Mode\n",
       " 2       Dispersion  Variance Standard deviation Coefficient of var...\n",
       " 3            Shape  Central limit theorem Moments Skewness Kurtosi...\n",
       " 4       Count data                                Index of dispersion\n",
       " 5   Summary tables  Grouped data Frequency distribution Contingenc...\n",
       " 6       Dependence  Pearson product-moment correlation Rank correl...\n",
       " 7         Graphics  Bar chart Biplot Box plot Control chart Correl...,\n",
       "             0                                                  1\n",
       " 0      Center     Mean arithmetic geometric harmonic Median Mode\n",
       " 1  Dispersion  Variance Standard deviation Coefficient of var...\n",
       " 2       Shape  Central limit theorem Moments Skewness Kurtosi...,\n",
       "                                      Data collection  \\\n",
       " 0  Study design Population Statistic Effect size ...   \n",
       " 1                                       Study design   \n",
       " 2                                 Survey methodology   \n",
       " 3                             Controlled experiments   \n",
       " 4                                   Adaptive Designs   \n",
       " 5                              Observational Studies   \n",
       " \n",
       "                                    Data collection.1  \n",
       " 0  Study design Population Statistic Effect size ...  \n",
       " 1  Population Statistic Effect size Statistical p...  \n",
       " 2  Sampling stratified cluster Standard error Opi...  \n",
       " 3  Scientific control Randomized experiment Rando...  \n",
       " 4  Adaptive clinical trial Up-and-Down Designs St...  \n",
       " 5  Cross-sectional study Cohort study Natural exp...  ,\n",
       "                         0                                                  1\n",
       " 0            Study design  Population Statistic Effect size Statistical p...\n",
       " 1      Survey methodology  Sampling stratified cluster Standard error Opi...\n",
       " 2  Controlled experiments  Scientific control Randomized experiment Rando...\n",
       " 3        Adaptive Designs  Adaptive clinical trial Up-and-Down Designs St...\n",
       " 4   Observational Studies  Cross-sectional study Cohort study Natural exp...,\n",
       "                                 Statistical inference  \\\n",
       " 0   Statistical theory Population Statistic Probab...   \n",
       " 1                                  Statistical theory   \n",
       " 2                               Frequentist inference   \n",
       " 3                                    Point estimation   \n",
       " 4                                 Interval estimation   \n",
       " 5                                  Testing hypotheses   \n",
       " 6                                    Parametric tests   \n",
       " 7                                      Specific tests   \n",
       " 8             Z-test (normal) Student's t-test F-test   \n",
       " 9                                     Goodness of fit   \n",
       " 10                                    Rank statistics   \n",
       " 11                                 Bayesian inference   \n",
       " \n",
       "                               Statistical inference.1  \n",
       " 0   Statistical theory Population Statistic Probab...  \n",
       " 1   Population Statistic Probability distribution ...  \n",
       " 2   Point estimation Estimating equations Maximum ...  \n",
       " 3   Estimating equations Maximum likelihood Method...  \n",
       " 4   Confidence interval Pivot Likelihood interval ...  \n",
       " 5   1- & 2-tails Power Uniformly most powerful tes...  \n",
       " 6     Likelihood-ratio Score/Lagrange multiplier Wald  \n",
       " 7   Z-test (normal) Student's t-test F-test Goodne...  \n",
       " 8             Z-test (normal) Student's t-test F-test  \n",
       " 9   Chi-squared G-test Kolmogorov–Smirnov Anderson...  \n",
       " 10  Sign Sample median Signed rank (Wilcoxon) Hodg...  \n",
       " 11  Bayesian probability prior posterior Credible ...  ,\n",
       "                                           0  \\\n",
       " 0                        Statistical theory   \n",
       " 1                     Frequentist inference   \n",
       " 2                          Point estimation   \n",
       " 3                       Interval estimation   \n",
       " 4                        Testing hypotheses   \n",
       " 5                          Parametric tests   \n",
       " 6                            Specific tests   \n",
       " 7   Z-test (normal) Student's t-test F-test   \n",
       " 8                           Goodness of fit   \n",
       " 9                           Rank statistics   \n",
       " 10                       Bayesian inference   \n",
       " \n",
       "                                                     1  \n",
       " 0   Population Statistic Probability distribution ...  \n",
       " 1   Point estimation Estimating equations Maximum ...  \n",
       " 2   Estimating equations Maximum likelihood Method...  \n",
       " 3   Confidence interval Pivot Likelihood interval ...  \n",
       " 4   1- & 2-tails Power Uniformly most powerful tes...  \n",
       " 5     Likelihood-ratio Score/Lagrange multiplier Wald  \n",
       " 6   Z-test (normal) Student's t-test F-test Goodne...  \n",
       " 7             Z-test (normal) Student's t-test F-test  \n",
       " 8   Chi-squared G-test Kolmogorov–Smirnov Anderson...  \n",
       " 9   Sign Sample median Signed rank (Wilcoxon) Hodg...  \n",
       " 10  Bayesian probability prior posterior Credible ...  ,\n",
       "                      0                                                  1\n",
       " 0     Point estimation  Estimating equations Maximum likelihood Method...\n",
       " 1  Interval estimation  Confidence interval Pivot Likelihood interval ...\n",
       " 2   Testing hypotheses  1- & 2-tails Power Uniformly most powerful tes...\n",
       " 3     Parametric tests    Likelihood-ratio Score/Lagrange multiplier Wald,\n",
       "                                          0  \\\n",
       " 0  Z-test (normal) Student's t-test F-test   \n",
       " 1                          Goodness of fit   \n",
       " 2                          Rank statistics   \n",
       " \n",
       "                                                    1  \n",
       " 0            Z-test (normal) Student's t-test F-test  \n",
       " 1  Chi-squared G-test Kolmogorov–Smirnov Anderson...  \n",
       " 2  Sign Sample median Signed rank (Wilcoxon) Hodg...  ,\n",
       "                       CorrelationRegression analysis  \\\n",
       " 0  Correlation Pearson product-moment Partial cor...   \n",
       " 1                                        Correlation   \n",
       " 2                                Regression analysis   \n",
       " 3                                  Linear regression   \n",
       " 4                            Non-standard predictors   \n",
       " 5                           Generalized linear model   \n",
       " 6                              Partition of variance   \n",
       " \n",
       "                     CorrelationRegression analysis.1  \n",
       " 0  Correlation Pearson product-moment Partial cor...  \n",
       " 1  Pearson product-moment Partial correlation Con...  \n",
       " 2  Errors and residuals Regression validation Mix...  \n",
       " 3  Simple linear regression Ordinary least square...  \n",
       " 4  Nonlinear regression Nonparametric Semiparamet...  \n",
       " 5  Exponential families Logistic (Bernoulli) / Bi...  \n",
       " 6  Analysis of variance (ANOVA, anova) Analysis o...  ,\n",
       "                           0                                                  1\n",
       " 0               Correlation  Pearson product-moment Partial correlation Con...\n",
       " 1       Regression analysis  Errors and residuals Regression validation Mix...\n",
       " 2         Linear regression  Simple linear regression Ordinary least square...\n",
       " 3   Non-standard predictors  Nonlinear regression Nonparametric Semiparamet...\n",
       " 4  Generalized linear model  Exponential families Logistic (Bernoulli) / Bi...\n",
       " 5     Partition of variance  Analysis of variance (ANOVA, anova) Analysis o...,\n",
       "    Categorical / Multivariate / Time-series / Survival analysis  \\\n",
       " 0   Categorical Cohen's kappa Contingency table Gr...             \n",
       " 1                                         Categorical             \n",
       " 2                                        Multivariate             \n",
       " 3                                         Time-series             \n",
       " 4                                             General             \n",
       " 5                                      Specific tests             \n",
       " 6                                         Time domain             \n",
       " 7                                    Frequency domain             \n",
       " 8                                            Survival             \n",
       " 9                                   Survival function             \n",
       " 10                                    Hazard function             \n",
       " 11                                               Test             \n",
       " \n",
       "    Categorical / Multivariate / Time-series / Survival analysis.1  \n",
       " 0   Categorical Cohen's kappa Contingency table Gr...              \n",
       " 1   Cohen's kappa Contingency table Graphical mode...              \n",
       " 2   Regression Manova Principal components Canonic...              \n",
       " 3   General Decomposition Trend Stationarity Seaso...              \n",
       " 4   Decomposition Trend Stationarity Seasonal adju...              \n",
       " 5   Dickey–Fuller Johansen Q-statistic (Ljung–Box)...              \n",
       " 6   Autocorrelation (ACF) partial (PACF) Cross-cor...              \n",
       " 7   Spectral density estimation Fourier analysis W...              \n",
       " 8   Survival function Kaplan–Meier estimator (prod...              \n",
       " 9   Kaplan–Meier estimator (product limit) Proport...              \n",
       " 10                             Nelson–Aalen estimator              \n",
       " 11                                      Log-rank test              ,\n",
       "                     0                                                  1\n",
       " 0         Categorical  Cohen's kappa Contingency table Graphical mode...\n",
       " 1        Multivariate  Regression Manova Principal components Canonic...\n",
       " 2         Time-series  General Decomposition Trend Stationarity Seaso...\n",
       " 3             General  Decomposition Trend Stationarity Seasonal adju...\n",
       " 4      Specific tests  Dickey–Fuller Johansen Q-statistic (Ljung–Box)...\n",
       " 5         Time domain  Autocorrelation (ACF) partial (PACF) Cross-cor...\n",
       " 6    Frequency domain  Spectral density estimation Fourier analysis W...\n",
       " 7            Survival  Survival function Kaplan–Meier estimator (prod...\n",
       " 8   Survival function  Kaplan–Meier estimator (product limit) Proport...\n",
       " 9     Hazard function                             Nelson–Aalen estimator\n",
       " 10               Test                                      Log-rank test,\n",
       "                   0                                                  1\n",
       " 0           General  Decomposition Trend Stationarity Seasonal adju...\n",
       " 1    Specific tests  Dickey–Fuller Johansen Q-statistic (Ljung–Box)...\n",
       " 2       Time domain  Autocorrelation (ACF) partial (PACF) Cross-cor...\n",
       " 3  Frequency domain  Spectral density estimation Fourier analysis W...,\n",
       "                    0                                                  1\n",
       " 0  Survival function  Kaplan–Meier estimator (product limit) Proport...\n",
       " 1    Hazard function                             Nelson–Aalen estimator\n",
       " 2               Test                                      Log-rank test,\n",
       "                                         Applications  \\\n",
       " 0  Biostatistics Bioinformatics Clinical trials /...   \n",
       " 1                                      Biostatistics   \n",
       " 2                             Engineering statistics   \n",
       " 3                                  Social statistics   \n",
       " 4                                 Spatial statistics   \n",
       " \n",
       "                                       Applications.1  \n",
       " 0  Biostatistics Bioinformatics Clinical trials /...  \n",
       " 1  Bioinformatics Clinical trials / studies Epide...  \n",
       " 2  Chemometrics Methods engineering Probabilistic...  \n",
       " 3  Actuarial science Census Crime statistics Demo...  \n",
       " 4  Cartography Environmental statistics Geographi...  ,\n",
       "                         0                                                  1\n",
       " 0           Biostatistics  Bioinformatics Clinical trials / studies Epide...\n",
       " 1  Engineering statistics  Chemometrics Methods engineering Probabilistic...\n",
       " 2       Social statistics  Actuarial science Census Crime statistics Demo...\n",
       " 3      Spatial statistics  Cartography Environmental statistics Geographi...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(table[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>White collar</td>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "      <td>104</td>\n",
       "      <td>95</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blue collar</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "      <td>20</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No collar</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Total</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>200</td>\n",
       "      <td>150</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0    A    B    C    D  total\n",
       "0  White collar   90   60  104   95    349\n",
       "1   Blue collar   30   50   51   20    151\n",
       "2     No collar   30   40   45   35    150\n",
       "3         Total  150  150  200  150    650"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['White collar', 'Blue collar', 'No collar', 'Total'] [array([90, 60, 104, 95], dtype=object), array([30, 50, 51, 20], dtype=object), array([30, 40, 45, 35], dtype=object), array([150, 150, 200, 150], dtype=object)]\n",
      "Combined [('White collar', array([90, 60, 104, 95], dtype=object)), ('Blue collar', array([30, 50, 51, 20], dtype=object)), ('No collar', array([30, 40, 45, 35], dtype=object)), ('Total', array([150, 150, 200, 150], dtype=object))]\n"
     ]
    }
   ],
   "source": [
    "names = []\n",
    "\n",
    "values = []\n",
    "for i in range(len(df)):\n",
    "    names.append(df.iloc[i][0])\n",
    "    values.append(np.array(df.iloc[i][1:-1]))\n",
    "print(names, values)\n",
    "combined = list(zip(names,values))\n",
    "print('Combined',combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  4 non-null      object\n",
      " 1   A           4 non-null      int64 \n",
      " 2   B           4 non-null      int64 \n",
      " 3   C           4 non-null      int64 \n",
      " 4   D           4 non-null      int64 \n",
      " 5   total       4 non-null      int64 \n",
      "dtypes: int64(5), object(1)\n",
      "memory usage: 320.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30 50 51 20]\n",
      "[array([90, 60, 104, 95], dtype=object), array([30, 50, 51, 20], dtype=object), array([30, 40, 45, 35], dtype=object), array([150, 150, 200, 150], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "print(combined[1][1])\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24.571202858582602,\n",
       " 0.003483988784534318,\n",
       " 9,\n",
       " array([[ 80.53846154,  80.53846154, 107.38461538,  80.53846154],\n",
       "        [ 34.84615385,  34.84615385,  46.46153846,  34.84615385],\n",
       "        [ 34.61538462,  34.61538462,  46.15384615,  34.61538462],\n",
       "        [150.        , 150.        , 200.        , 150.        ]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.chi2_contingency(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi Stat and Chi-square Test\n",
    "**The Chi Stat is 24.57** from the above output which verifies the value given in the Wikipedia article. The Chi stat is calculated by analysing the difference between the observed and expected distributions.  Χ2 = Σ (O − E)2E / E\n",
    "\n",
    "The chi-square test is used to test for a possible relationship between variables.  The more the observations differ from the expected distribution, the greater the chance that the variables are dependent.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degrees of Freedom\n",
    "The degrees of freedom is 9 in this the above table. This is a measure of how many independent observations can be made. Generally, the higher the degrees of freedom is, the more relevant the Chi Square test will be.\n",
    "\n",
    "Degrees of freedom is used in the calculation of the P value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The P Value\n",
    "**The P-value is 0.003** which indicates that neighbourhood (A,B,C,D) and type of worker living there are not independent. The difference between the expected distribution of types of worker in each area and the actual distribution is large enough to indicate that the neighbourhood and category of worker are"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html\n",
    "\n",
    "https://towardsdatascience.com/running-chi-square-tests-in-python-with-die-roll-data-b9903817c51b\n",
    "\n",
    "https://www.investopedia.com/terms/d/degrees-of-freedom.asp\n",
    "\n",
    "https://towardsdatascience.com/chi-squared-test-for-feature-selection-with-implementation-in-python-65b4ae7696db\n",
    "\n",
    "https://www.mathsisfun.com/data/chi-square-test.html\n",
    "\n",
    "https://machinelearningmastery.com/chi-squared-test-for-machine-learning/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excel Function STDEV.P\n",
    "\n",
    "The Excel function **STDEV.P** calculates the Standard Deviation when the values for every member of a population is known and we wish to know the standard deviation.  The function takes every member of an array representing the entire population as its arguments.  Importantly, in contrast with STDEV.S, this function uses the \"n\" method and the following formula √[∑(x - x̃)²/n]  .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excel Function STDEV.S\n",
    "\n",
    "**STDEV.S** is an Excel function which calculates the Standard Deviation of a sample contained within a population. For most real-life scenarios, this is the best way to calculate the standard deviation as very often we do not have access to the entire target population.  This function uses the \"n-1\" method. \"n-1\" is a type of correction when calculating the standard deviation from only a sample of the total population.  The observed values are usually closer to the sample mean than to the real population mean.  Therefore using \"n-1\" corrects for this anticipated error by making the standard deviation larger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### numpy Simulation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Standard Deviation: 2879.7606598396387\n",
      "Sample Standard Deviation STDEV_P: 2774.158624091815\n",
      "Sample Standard Deviation STDEV_S: 2821.583574377375\n"
     ]
    }
   ],
   "source": [
    "# Generate random 1d array as population\n",
    "\n",
    "\n",
    "STDEV_P = 0\n",
    "STDEV_S = 0\n",
    "actual = 0\n",
    "# calculate std dev of population using \"n\" method (default in numpy)\n",
    "# this figure represents the actual standard deviation!\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    # Generate random 1d array as population\n",
    "    population = np.random.randint(1,1000,80)\n",
    "\n",
    "    n_method = np.std(population)\n",
    "    actual += n_method\n",
    "\n",
    "    # take a sample of the population\n",
    "\n",
    "    sample = np.random.choice(population,30)\n",
    "\n",
    "\n",
    "    # calculate std deviation of sample using  \"n\" method\n",
    "\n",
    "\n",
    "    n_method_sample = np.std(sample)\n",
    "    STDEV_P += n_method_sample\n",
    "\n",
    "\n",
    "    # calculate std deviatian of sample using \"n-1\"\n",
    "\n",
    "    n_1_method_sample = np.std(sample, ddof =1)\n",
    "    STDEV_S += n_1_method_sample\n",
    "\n",
    "    \n",
    "print(\"Actual Standard Deviation: {}\\nSample Standard Deviation STDEV_P: {}\\nSample Standard Deviation STDEV_S: {}\".format(actual,STDEV_P,STDEV_S))\n",
    "\n",
    "     \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 16, 590, 862, 469, 720,  43, 419, 253, 859, 248, 484, 141, 785,\n",
       "       771, 111, 810, 208, 538, 488, 142, 843, 681, 881, 815, 582, 210,\n",
       "       155, 218, 483, 580, 118, 867, 238, 606, 155, 770, 321, 588, 995,\n",
       "       705, 785, 804, 890, 531, 793, 576, 995, 220, 933, 696, 177, 551,\n",
       "       221, 384, 434, 305,  29, 769, 580, 896, 306, 818, 315, 973, 849,\n",
       "        49, 639, 892, 967, 931, 930, 810, 608, 861, 388, 174, 584, 880,\n",
       "       840, 540])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate random 1d array as population\n",
    "\n",
    "population = np.random.randint(1,1000,80)\n",
    "population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289.56308655239536"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate std dev of population using \"n\" method (default in numpy)\n",
    "# this figure represents the actual standard deviation!\n",
    "\n",
    "n_method = np.std(population)\n",
    "n_method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([810, 859, 210, 892, 840, 221, 861, 892, 177, 608, 881, 849, 538,\n",
       "       582, 720, 892, 804, 305, 785, 861, 933, 469, 861, 588, 804, 238,\n",
       "       785,  43, 880, 177])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a sample of the population\n",
    "\n",
    "sample = np.random.choice(population,30)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "285.6917219661781"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate std deviation of sample using  \"n\" method\n",
    "\n",
    "n_method_sample = np.std(sample)\n",
    "n_method_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290.5756949277737"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate std deviatian of sample using \"n-1\"\n",
    "\n",
    "n_1_method_sample = np.std(sample, ddof =1)\n",
    "n_1_method_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "https://support.microsoft.com/en-us/office/stdev-p-function-6e917c05-31a0-496f-ade7-4f4e7462f285\n",
    "\n",
    "https://stats.stackexchange.com/questions/3931/intuitive-explanation-for-dividing-by-n-1-when-calculating-standard-deviation#:~:text=The%20standard%20deviation%20calculated%20with%20a%20divisor%20of,the%20population%20from%20which%20the%20sample%20was%20drawn.\n",
    "\n",
    "https://honingds.com/blog/python-standard-deviation/#:~:text=numpy%20uses%20population%20standard%20deviation%20by%20default%2C%20which,using%20numpy.std%20for%20a%20sample%20of%20the%20data.\n",
    "\n",
    "https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.random.choice.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'C:\\\\Users\\\\Corma\\\\anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\iris.csv'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_iris()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.datasciencelearner.com/k-means-clustering-in-python-label-dataset/#:~:text=%20K%20Means%20Clustering%20in%20Python%20%3A%20Label,can%20also%20use%20your%20own%20dataset.%20More%20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
